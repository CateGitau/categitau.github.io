---
layout: post
title: Using rvest to scrape data from Wikipedia
date: 2018-02-14 16:39:55.000000000 +00:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories: []
tags: []
meta:
  _jetpack_related_posts_cache: a:1:{s:32:"8f6677c9d6b0f903e98ad32ec61f8deb";a:2:{s:7:"expires";i:1583704749;s:7:"payload";a:3:{i:0;a:1:{s:2:"id";i:668;}i:1;a:1:{s:2:"id";i:1692;}i:2;a:1:{s:2:"id";i:1759;}}}}
  _edit_last: '1'
  _syntaxhighlighter_encoded: '1'
  _thumbnail_id: '1677'
  _wpas_done_all: '1'
  _oembed_832785e9c969ea5221271fcae0e57827: '<blockquote class="wp-embedded-content"
    data-secret="J4OZKsvodN"><a href="https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/">Beginner’s
    Guide on Web Scraping in R (using rvest) with hands-on example</a></blockquote><iframe
    class="wp-embedded-content" sandbox="allow-scripts" security="restricted" style="position:
    absolute; clip: rect(1px, 1px, 1px, 1px);" src="https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/embed/#?secret=J4OZKsvodN"
    data-secret="J4OZKsvodN" width="600" height="338" title="&#8220;Beginner’s Guide
    on Web Scraping in R (using rvest) with hands-on example&#8221; &#8212; Analytics
    Vidhya" frameborder="0" marginwidth="0" marginheight="0" scrolling="no"></iframe>'
  _oembed_time_832785e9c969ea5221271fcae0e57827: '1518608084'
  _facebook_shares: '0'
  swp_pinterest_image_url: ''
  swp_cache_timestamp: '431868'
  _totes: '0'
  _pinterest_shares: '0'
  _twitter_shares: '0'
  _linkedin_shares: '0'
  _google_plus_shares: '0'
  _total_shares: '0'
author:
  login: categitau
  email: catherinegitau94@gmail.com
  display_name: categitau
  first_name: ''
  last_name: ''
permalink: "/using-rvest-to-scrape-data-from-wikipedia/"
---
<p>&nbsp;</p>
<blockquote><p><strong>Web scraping</strong>, <strong>web harvesting</strong> or <strong>web data extraction</strong> is <a href="https://en.wikipedia.org/wiki/Data_scraping">data scraping</a> used for extracting data from websites.</p>
<p><em>-Wikipedia</em></p></blockquote>
<p>A couple of days ago, I was looking for project ideas on <a href="https://medium.com/"><strong>medium</strong></a> and I remembered having stumbled upon this <a href="https://medium.com/@jasonkgoodman/advice-on-building-data-portfolio-projects-c5f96d8a0627"> post</a>  sometime back which gives advice on <em>building data portfolio projects</em>. At the end of the post, the author pitched a project idea on finding out the divorce rates of actors and actresses on Wikipedia. I decided to take up the challenge and see if I can actually scrape the biography pages of actors and actresses on Wikipedia and get any interesting insights then finally build a model around it.</p>
<p>This post will highlight how I got to scraping out this data using R's package <strong>rvest. rvest</strong> is an R package that makes it easy for us to scrape data from the web. So, brace yourselves, technical post ahead!</p>
<h4>1. Getting Started</h4>
<h5>Pre-requisites:</h5>
<ul>
<li>To get started with web scraping in R you'll obviously need some working knowledge of R programming language.</li>
<li>Throughout this post/tutorial we'll be working with the rvest package which you can install using the following code:</li>
</ul>
<p>[sourcecode language="r"]</p>
<p>install.packages(&quot;rvest&quot;)</p>
<p>[/sourcecode]</p>
<ul>
<li>Some knowledge of HTML and CSS will also be an added advantage. If you don't have any knowledge on HTML and CSS, worry not, you can use an opensource software known as Selector Gadget. You can simply access it by downloading the Selector Gadget extension from <a href="http://selectorgadget.com/">this</a> website . Using the extension you can select the parts of any website and get the relevant tags by simply clicking on the part of the website you'd like to scrape out.</li>
<li>Finally, you also need Google chrome.</li>
</ul>
<p>Awesome! Now, let's get started on scraping Wikipedia:</p>
<h4>2. Scraping Wikipedia using R</h4>
<ul>
<li>
<h5>Step 1</h5>
</li>
</ul>
<p>After searching through <a href="https://www.wikipedia.org/">Wikipedia's website</a>, I came across <a href="https://en.wikipedia.org/wiki/List_of_American_film_actresses">this</a> page that has a list of around 1500 american actresses and links to their Wikipedia pages where you can access more information about them.</p>
<p>[caption id="attachment_1667" align="alignnone" width="676"]<img class="wp-image-1667 size-large" src="{{ site.baseurl }}/assets/Capture-700x163.png" alt="" width="676" height="157" /> List of American actresses[/caption]</p>
<p>below is a screenshot of Jennifer Aniston's Wikipedia page that we're going to scrape. The highlighted part is the part we need in this case. It contains information about the actor's place and date of birth, occupation e.t.c.</p>
<p>[caption id="attachment_1669" align="alignnone" width="1187"]<img class="wp-image-1669 size-full" src="{{ site.baseurl }}/assets/Screenshot-14.png" alt="" width="1187" height="668" /> Highlighted Wikipedia page using Selector Gadget[/caption]</p>
<p>I've actually highlighted that part using <a href="https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en">Selector Gadget</a>, which helps in getting the specific CSS selectors that we want to use so as to scrape the page. From the screenshot above, at the bottom middle you can see that our CSS selector for the highlighted biography table is <em><strong>".vcard" </strong></em>which we are going to need later<em><strong>.</strong></em> You could also use Google Chrome's developer tools to look at the HTML behind the biography table as shown highlighted in the screenshot below and copy the CSS selector by right clicking on the html code.</p>
<p><img class="alignnone wp-image-1678 size-full" src="{{ site.baseurl }}/assets/Screenshot-16.jpg" alt="" width="1219" height="479" /></p>
<p>&nbsp;</p>
<ul>
<li>
<h5>Step 2</h5>
</li>
</ul>
<p>To read the web page into R we will need the rvest package and also the <a href="https://cran.r-project.org/web/packages/magrittr/index.html">magrittr</a> package which uses the operator <strong>%&lt;%</strong> that takes the output from the left and uses it as the first argument of input on the right.</p>
<p>[sourcecode langauge="r"]</p>
<p>#load in the Rvest and magrittr package</p>
<p>library(rvest)</p>
<p>library(magrittr)</p>
<p>[/sourcecode]</p>
<p>The function we're going to use first is the <em><strong>read_html()</strong></em> which is used in reading HTML pages. You do this using the following code:</p>
<p>[sourcecode language="r"]<br />
#read HTML code from the website<br />
webpage &lt;- read_html(&quot;https://en.wikipedia.org/wiki/Jennifer_Aniston&quot;)<br />
[/sourcecode]</p>
<p>Next, since we have already identified our CSS selector <em><strong>"v.card"</strong></em>, we use the following code to extract the information<br />
in the biography table.</p>
<p>[sourcecode language="r"]<br />
table &lt;- webpage %&lt;%<br />
html_nodes(&quot;table.vcard&quot;) %&lt;%<br />
html_table(header=F)<br />
table &lt;- table[[1]]</p>
<p>#add the table to a dataframe<br />
dict &lt;- as.data.frame(table)</p>
<p>[/sourcecode]</p>
<p>We then come up with the table below:<br />
<img class="alignnone wp-image-1674 size-full" src="{{ site.baseurl }}/assets/Capture-1.png" alt="" width="515" height="236" /></p>
<p>Easy right?</p>
<h5>Conclusion</h5>
<p>So, you've just learnt how to scrape a html table from a web page using R. A lot goes into the code when scraping each bio table from the list of actresses. You can access the code and data I extracted <a href="https://github.com/CateGitau/Web-Scraping-in-R">here</a>.</p>
<h5>References</h5>
<p>Analytics Vidhya, Beginner's guide on web scraping - <a href="https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/">https://www.analyticsvidhya.com/blog/2017/03/beginners-guide-on-web-scraping-in-r-using-rvest-with-hands-on-knowledge/</a></p>
<p>&nbsp;</p>
<p>Till next time :)</p>
<p>&nbsp;</p>
